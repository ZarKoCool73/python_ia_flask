<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebRTC App</title>
</head>
<style>
    *{
        box-sizing: border-box;
    }
    .container_video{
        display: flex;
        flex-direction: column;
        width: 100vw;
        height: 100vh;
        align-items: center;
    }
    .container_video> video{
        width: 83vw;
    }
    button {
            background: none;
            border: none;
            padding: 0;
            margin: 0;
            cursor: pointer;
        }

    .button{
        border-color: #3A7734;
        margin-top: 15px;
        border-radius: 10px;
        background-color: #3A7734;
        color: white;
        font-size: 18px;
        padding: 10px;
    }
</style>
<body style="padding: 0; margin: 0">
<div class="container_video">
    <video id="localVideo" autoplay></video>
    <video id="remoteVideo" style="display: none" autoplay></video>
    <button id="captureButton" class="button">Capturar Imagen</button>

</div>

<canvas id="canvas" style="display:none;"></canvas>

<div id="detectedSign"></div>
<script>
    const localVideo = document.getElementById('localVideo');
    const remoteVideo = document.getElementById('remoteVideo');
    const canvas = document.getElementById('canvas');
    const context = canvas.getContext('2d');
    const capturedImage = document.getElementById('capturedImage');
    const captureButton = document.getElementById('captureButton');
    let peerConnection;

    async function setupWebRTC() {
        const stream = await navigator.mediaDevices.getUserMedia({video: true, audio: false});
        localVideo.srcObject = stream;

        const configuration = {iceServers: [{urls: 'stun:stun.l.google.com:19302'}]};
        peerConnection = new RTCPeerConnection(configuration);

        stream.getTracks().forEach(track => peerConnection.addTrack(track, stream));

        peerConnection.ontrack = event => {
            remoteVideo.srcObject = event.streams[0];
        };
        captureButton.addEventListener('click', () => {
            // Asignar el ancho y alto del canvas para que coincida con el tamaño del video
            canvas.width = localVideo.videoWidth;
            canvas.height = localVideo.videoHeight;

            // Dibujar el fotograma actual del video local en el canvas
            context.drawImage(localVideo, 0, 0, canvas.width, canvas.height);

            const imgData = canvas.toDataURL('image/jpeg')

            console.log(window.location.href)
            console.log(window.location.href.includes('expressions'))

            const response = fetch('/process_image', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    imageData: imgData
                })
            })

            const data = response.json()

            // Mostrar imagen procesada
            //processedImg.src = data.image

            // Mostrar signo detectado
         //   detectedSign.innerText = data.sign
        });
    }

    setupWebRTC().catch(error => console.error('Error en la configuración de WebRTC:', error));
</script>
</body>
</html>